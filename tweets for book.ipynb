{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates how many tweets a book of tanakh would be, if you tweeted it out, allowing for breaking sentences but not words\n",
    "\n",
    "import json, urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textpuller(text):\n",
    "    link = \"https://www.sefaria.org/api/texts/\"+text+\"?vhe=Miqra_according_to_the_Masorah&context=0\"\n",
    "    print(link) #prints link to make troubleshooting easier\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        sefariaresult = json.loads(url.read().decode())\n",
    "    text = \"\"\n",
    "    if type(sefariaresult[\"he\"])==str:\n",
    "        text = sefariaresult[\"he\"]\n",
    "    elif type(sefariaresult[\"he\"])==list:\n",
    "        if type(sefariaresult[\"he\"][0])==str:\n",
    "            for verse in sefariaresult[\"he\"]:\n",
    "                text = text + verse + \" \"\n",
    "        elif type(sefariaresult[\"he\"][0])==list:\n",
    "            textblock = []\n",
    "            for chunk in sefariaresult[\"he\"]:\n",
    "                textblock = textblock + chunk\n",
    "            for verse in textblock:\n",
    "                text = text + verse + \" \"\n",
    "    title_he = sefariaresult[\"heSectionRef\"]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeformatting(text): #removes all formatting statements in <>\n",
    "    while \"<\" in text and \">\" in text:\n",
    "        loc1 = text.find(\"<\")\n",
    "        loc2 = text.find(\">\",loc1)+1\n",
    "        text = text.replace(text[loc1:loc2],\"\")\n",
    "    return text\n",
    "\n",
    "def qkparse(string): #takes every kri ukhtiv, returns the text with the ketiv only\n",
    "    start = string.index('<span class=\\\"mam-kq\">')\n",
    "    string_before = string[0:start]\n",
    "    startk = string.index('<span class=\\\"mam-kq-k\\\">',start)\n",
    "    startk = string.index('>',startk)+2\n",
    "    endk = string.index('</span>',startk)-1\n",
    "    ktext = string[startk:endk]\n",
    "    startq = string.index('<span class=\\\"mam-kq-q\\\">')\n",
    "    startq = string.index('>',startq)+2\n",
    "    endq = string.index('</span>',startq)-1\n",
    "    qtext=string[startq:endq]\n",
    "    end = string.index('</span></span>',endq)\n",
    "    end = string.index(' ',end)\n",
    "    output = '\\\\qk{'+qtext+'}{'+ktext+'}'\n",
    "    string_after = string[end:]\n",
    "    return string_before + ktext+string_after\n",
    "\n",
    "def nonalpha_remover(word):\n",
    "    no_cant_word = ''\n",
    "    for letter in word:\n",
    "        if letter.isalpha() == True or letter == \" \":\n",
    "            no_cant_word = no_cant_word + letter\n",
    "    return no_cant_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sefaria.org/api/texts/Ruth.1-4?vhe=Miqra_according_to_the_Masorah&context=0\n",
      "4953 letters 23 tweets\n"
     ]
    }
   ],
   "source": [
    "text = textpuller(\"Ruth.1-4\") #need name of book, first and last chapter numbers\n",
    "while '<span class=\\\"mam-kq\">' in text:\n",
    "    text = qkparse(text)\n",
    "repeat = \"<small>סוף דבר הכל נשמע את האלהים ירא ואת מצותיו שמור כי זה כל האדם</small>\" #accounts for repeated thing at the end of kohelet\n",
    "#probably needs to also catch the repeat at the end of Eicha\n",
    "text = text.replace(repeat,\"\")\n",
    "text = removeformatting(text) #removes everything in <>\n",
    "text = text.replace(\"{ס}\",\"\") #removes marker for parsha setuma, which has one letter that otherwise would be counted\n",
    "text = text.replace(\"{פ}\",\"\") #removes marker for parsha petucha, which has the same\n",
    "text = text.replace(\"־\",\" \") #replaces maqqaf with a space, since that's how it appears in the consonant text\n",
    "text = text.replace(\"  \",\" \")#replaces double space with single space\n",
    "text = nonalpha_remover(text) #removes all non-letters, i.e. vowels, tropp marks, &c\n",
    "charcounter = 0 #counts characters\n",
    "char_reset = 0 #counts characters within a tweet\n",
    "tweetcounter = 0 #counts tweets\n",
    "words = text.split(\" \") #splits text into a list of words\n",
    "for word in words:\n",
    "    charcounter += len(word) #add to the charcounter how many letters are in this word\n",
    "    char_reset += len(word) #and do the same within the tweet\n",
    "    if char_reset > 280: #if that makes the tweet too long\n",
    "        tweetcounter += 1 #that's one more tweet\n",
    "        char_reset = len(word) #reset within-tweet counter to count the number of letters in the word that couldn't be tweeted\n",
    "    else:\n",
    "        char_reset += 1 #adds a counter for a space, since tweets have spaces between words and that counts as a character\n",
    "        #but not if it's a new tweet\n",
    "tweetcounter += 1 #counts the partially-filled tweet\n",
    "print(charcounter, \"letters\", tweetcounter, \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
